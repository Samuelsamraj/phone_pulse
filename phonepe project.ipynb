{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31c46d7-073b-4ecb-bd73-740e6150ba54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pulse' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git clone https://github.com/PhonePe/pulse.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f3dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804627b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272fa78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23a9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd67c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05305ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87cc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c949256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4b5802b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agg_Trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21306e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c07cc38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\docs\\Projects\\Phonepe_pulse\\Miscellaneous\\Pulse\\data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from git import Repo\n",
    "           \n",
    "repo_url = \"https://github.com/PhonePe/pulse.git\"\n",
    "#clone_path = \"C:\\ProgramFiles\\Phonepe_Pulse\\Miscellaneous\"\n",
    "clone_path = r\"C:\\docs\\Projects\\Phonepe_pulse\\Miscellaneous\"\n",
    "if not os.path.exists(clone_path):\n",
    "    os.makedirs(clone_path)\n",
    "\n",
    "repo_path = os.path.join(clone_path, os.path.basename(repo_url).split('.')[0].title())\n",
    "\n",
    "Repo.clone_from(repo_url, repo_path)\n",
    "\n",
    "directory = os.path.join(repo_path, 'data')\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "483d4951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rename messy state names in a proper format\n",
    "\n",
    "def rename(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if 'state' in dirs:\n",
    "            state_dir = os.path.join(root, 'state')\n",
    "            for state_folder in os.listdir(state_dir):\n",
    "                # rename the state folder\n",
    "                old_path = os.path.join(state_dir, state_folder)\n",
    "                new_path = os.path.join(state_dir, state_folder.title().replace('-', ' ').replace('&', 'and'))\n",
    "                os.rename(old_path, new_path)\n",
    "    print(\"Renamed all sub-directories successfully\")\n",
    "                \n",
    "# Function to extract all paths that has sub-directory in the name of 'state'\n",
    "\n",
    "def extract_paths(directory):\n",
    "    path_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if os.path.basename(root) == 'state':\n",
    "            path_list.append(root.replace('\\\\', '/'))\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdb34696-7158-4ebd-8b4e-3381d3a5dfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed all sub-directories successfully\n"
     ]
    }
   ],
   "source": [
    "rename(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d243d5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/aggregated/transaction/country/india/state',\n",
       " 'C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/aggregated/user/country/india/state',\n",
       " 'C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/map/transaction/hover/country/india/state',\n",
       " 'C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/map/user/hover/country/india/state',\n",
       " 'C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/top/transaction/country/india/state',\n",
       " 'C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/top/user/country/india/state']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_directories = extract_paths(directory)\n",
    "state_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd684707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/aggregated/transaction/country/india/state',\n",
       " 'C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/aggregated/user/country/india/state',\n",
       " 'C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/map/transaction/hover/country/india/state',\n",
       " 'C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/map/user/hover/country/india/state',\n",
       " 'C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/top/transaction/country/india/state',\n",
       " 'C:/docs/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/top/user/country/india/state']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_directories = extract_paths(directory)\n",
    "state_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa134c30-eee0-438b-9323-111d7f2ee862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframes from cloned json files\n",
    "#1. Aggregate Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ef5dbf4-d58c-40f8-aede-d5315e06c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[0]\n",
    "state_list = os.listdir(state_path)\n",
    "agg_trans_dict = {\n",
    "                  'State': [], 'Year': [], 'Quarter': [], 'Transaction_type': [],\n",
    "                  'Transaction_count': [], 'Transaction_amount': []\n",
    "                  }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for transaction_data in df['data']['transactionData']:\n",
    "                    \n",
    "                    type = transaction_data['name']\n",
    "                    count = transaction_data['paymentInstruments'][0]['count']\n",
    "                    amount = transaction_data['paymentInstruments'][0]['amount']\n",
    "                    \n",
    "                    # Appending to agg_trans_dict\n",
    "                    \n",
    "                    agg_trans_dict['State'].append(state)\n",
    "                    agg_trans_dict['Year'].append(year)\n",
    "                    agg_trans_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    agg_trans_dict['Transaction_type'].append(type)\n",
    "                    agg_trans_dict['Transaction_count'].append(count)\n",
    "                    agg_trans_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "agg_trans_df = pd.DataFrame(agg_trans_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "52d966dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agg_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3de0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c03d18-fcd8-4203-83c3-e9f0566c6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aggregate User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbe022c8-1405-4fb2-bd7c-7b8f368c7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[1]\n",
    "state_list = os.listdir(state_path)\n",
    "agg_user_dict = {\n",
    "                 'State': [], 'Year': [], 'Quarter': [], 'Brand': [],\n",
    "                 'Transaction_count': [], 'Percentage': []\n",
    "                 }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for user_data in df['data']['usersByDevice']:\n",
    "\n",
    "                    brand = user_data['brand']\n",
    "                    count = user_data['count']\n",
    "                    percent = user_data['percentage']\n",
    "                    \n",
    "                    # Appending to agg_user_dict\n",
    "                    \n",
    "                    agg_user_dict['State'].append(state)\n",
    "                    agg_user_dict['Year'].append(year)\n",
    "                    agg_user_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    agg_user_dict['Brand'].append(brand)\n",
    "                    agg_user_dict['Transaction_count'].append(count)\n",
    "                    agg_user_dict['Percentage'].append(percent)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "agg_user_df = pd.DataFrame(agg_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fa33aaa2-f1ca-4b0d-9f8b-f6b39a953081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agg_user_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8155c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b20b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Map Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21075e2c-0af0-4fc9-9ccc-3d4b47ab6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[2]\n",
    "state_list = os.listdir(state_path)\n",
    "map_trans_dict = {\n",
    "                    'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                    'Transaction_count': [], 'Transaction_amount': []\n",
    "                    }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for transaction_data in df['data']['hoverDataList']:\n",
    "                   \n",
    "                    district = transaction_data['name']\n",
    "                    count = transaction_data['metric'][0]['count']\n",
    "                    amount = transaction_data['metric'][0]['amount']\n",
    "                    \n",
    "                    # Appending to map_trans_dict\n",
    "                    \n",
    "                    map_trans_dict['State'].append(state)\n",
    "                    map_trans_dict['Year'].append(year)\n",
    "                    map_trans_dict['Quarter'].append(int(quarter.removesuffix('.json'))) \n",
    "                    map_trans_dict['District'].append(district.removesuffix(' district').title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    map_trans_dict['Transaction_count'].append(count)\n",
    "                    map_trans_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_trans_df = pd.DataFrame(map_trans_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4e7efa16-8131-42b0-ab69-fdbe85c4c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfc5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaafa319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9988ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Map User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "723726f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_path = state_directories[3]\n",
    "state_list = os.listdir(state_path)\n",
    "map_user_dict = {\n",
    "                 'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                 'Registered_users': [], 'App_opens': []\n",
    "                 }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district, user_data in df['data']['hoverData'].items():\n",
    "                    \n",
    "                    reg_user_count = user_data['registeredUsers']\n",
    "                    app_open_count = user_data['appOpens']\n",
    "                    \n",
    "                    # Appending to map_user_dict\n",
    "                    \n",
    "                    map_user_dict['State'].append(state)\n",
    "                    map_user_dict['Year'].append(year)\n",
    "                    map_user_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    map_user_dict['District'].append(district.removesuffix(' district').title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    map_user_dict['Registered_users'].append(reg_user_count)\n",
    "                    map_user_dict['App_opens'].append(app_open_count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_user_df = pd.DataFrame(map_user_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "13e6a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #map_user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0561905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Top Transaction District-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9280a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[4]\n",
    "state_list = os.listdir(state_path)\n",
    "top_trans_dist_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                        'Transaction_count': [], 'Transaction_amount': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district_data in df['data']['districts']:\n",
    "                    \n",
    "                    name = district_data['entityName']\n",
    "                    count = district_data['metric']['count']\n",
    "                    amount = district_data['metric']['amount']\n",
    "                    \n",
    "                    # Appending to top_trans_dist_dict\n",
    "                    \n",
    "                    top_trans_dist_dict['State'].append(state)\n",
    "                    top_trans_dist_dict['Year'].append(year)\n",
    "                    top_trans_dist_dict['Quarter'].append(int(quarter.removesuffix('.json')))                    \n",
    "                    top_trans_dist_dict['District'].append(name.title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    top_trans_dist_dict['Transaction_count'].append(count)\n",
    "                    top_trans_dist_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_trans_dist_df = pd.DataFrame(top_trans_dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "af3993ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_trans_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "88ef8501",
   "metadata": {},
   "outputs": [],
   "source": [
    " #6. Top Transaction Pincode-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "382d2183",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[4]\n",
    "state_list = os.listdir(state_path)\n",
    "top_trans_pin_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [], 'Pincode': [],\n",
    "                        'Transaction_count': [], 'Transaction_amount': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for regional_data in df['data']['pincodes']:\n",
    "                    \n",
    "                    name = regional_data['entityName']\n",
    "                    count = regional_data['metric']['count']\n",
    "                    amount = regional_data['metric']['amount']\n",
    "                    \n",
    "                    # Appending to top_trans_pin_dict\n",
    "                    \n",
    "                    top_trans_pin_dict['State'].append(state)\n",
    "                    top_trans_pin_dict['Year'].append(year)\n",
    "                    top_trans_pin_dict['Quarter'].append(int(quarter.removesuffix('.json')))                    \n",
    "                    top_trans_pin_dict['Pincode'].append(name)\n",
    "                    top_trans_pin_dict['Transaction_count'].append(count)\n",
    "                    top_trans_pin_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_trans_pin_df = pd.DataFrame(top_trans_pin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d7d7ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_trans_pin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c646f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Top User District-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6eb69a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[5]\n",
    "state_list = os.listdir(state_path)\n",
    "top_user_dist_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [],\n",
    "                        'District': [], 'Registered_users': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district_data in df['data']['districts']:\n",
    "                    \n",
    "                    name = district_data['name']\n",
    "                    count = district_data['registeredUsers']\n",
    "                    \n",
    "                    # Appending to top_user_dist_dict\n",
    "                    \n",
    "                    top_user_dist_dict['State'].append(state)\n",
    "                    top_user_dist_dict['Year'].append(year)\n",
    "                    top_user_dist_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    top_user_dist_dict['District'].append(name.title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    top_user_dist_dict['Registered_users'].append(count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_user_dist_df = pd.DataFrame(top_user_dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4f9c88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_user_dist_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b0de09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Top User Pincode-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e9603fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[5]\n",
    "state_list = os.listdir(state_path)\n",
    "top_user_pin_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [],\n",
    "                        'Pincode': [], 'Registered_users': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for regional_data in df['data']['pincodes']:\n",
    "                    \n",
    "                    name = regional_data['name']\n",
    "                    count = regional_data['registeredUsers']\n",
    "                    \n",
    "                    # Appending to top_user_pin_dict\n",
    "                    \n",
    "                    top_user_pin_dict['State'].append(state)\n",
    "                    top_user_pin_dict['Year'].append(year)\n",
    "                    top_user_pin_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    top_user_pin_dict['Pincode'].append(name)\n",
    "                    top_user_pin_dict['Registered_users'].append(count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_user_pin_df = pd.DataFrame(top_user_pin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c658c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_user_pin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc166d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of dataframes created so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ac05ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agg_trans_df',\n",
       " 'agg_user_df',\n",
       " 'map_trans_df',\n",
       " 'map_user_df',\n",
       " 'top_trans_dist_df',\n",
       " 'top_trans_pin_df',\n",
       " 'top_user_dist_df',\n",
       " 'top_user_pin_df',\n",
       " 'lat_long_df']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [df for df in globals() if isinstance(globals()[df], pd.core.frame.DataFrame) and df.endswith('_df')]\n",
    "\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98469d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([1, 2, 3], [4, 5, 6])\n",
    "\n",
    "st.pyplot(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st.pyplot(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4626f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming Delhi districts to manage inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc82931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As I noticed few district name is mismatched between dfs loaded from pulse and lat_long_df, doing this.\n",
    "\n",
    "def add_suffix_to_districts(df):\n",
    "    if 'District' in df.columns and 'State' in df.columns:\n",
    "        delhi_df = df[df['State'] == 'Delhi']\n",
    "        \n",
    "        districts_to_suffix = [d for d in delhi_df['District'].unique() if d != 'Shahdara']\n",
    "        \n",
    "        df.loc[(df['State'] == 'Delhi') & (df['District'].isin(districts_to_suffix)), 'District'] = df.loc[(df['State'] == 'Delhi') & (df['District'].isin(districts_to_suffix)), 'District'].apply(lambda x: x + ' Delhi' if 'Delhi' not in x else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    add_suffix_to_districts(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Latitude and Longitude columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5dae82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_df = pd.read_csv(\"C:\\phone pe\\Phonepe_Pulse\\Miscellaneous\\dist_lat_long.csv\")\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    if 'District' in df.columns:\n",
    "        df = pd.merge(df, lat_long_df, on=['State', 'District'], how='left')\n",
    "        globals()[df_name] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ba7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d69ea7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba797b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a703fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b6a78dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7427e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4df5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f9d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af01be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b2a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Region column to all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b77b0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_region_column(df):\n",
    "    state_groups = {\n",
    "        'Northern Region': ['Jammu and Kashmir', 'Himachal Pradesh', 'Punjab', 'Chandigarh', 'Uttarakhand', 'Ladakh', 'Delhi', 'Haryana'],\n",
    "        'Central Region': ['Uttar Pradesh', 'Madhya Pradesh', 'Chhattisgarh'],\n",
    "        'Western Region': ['Rajasthan', 'Gujarat', 'Dadra and Nagar Haveli and Daman and Diu', 'Maharashtra'],\n",
    "        'Eastern Region': ['Bihar', 'Jharkhand', 'Odisha', 'West Bengal', 'Sikkim'],\n",
    "        'Southern Region': ['Andhra Pradesh', 'Telangana', 'Karnataka', 'Kerala', 'Tamil Nadu', 'Puducherry', 'Goa', 'Lakshadweep', 'Andaman and Nicobar Islands'],\n",
    "        'North-Eastern Region': ['Assam', 'Meghalaya', 'Manipur', 'Nagaland', 'Tripura', 'Arunachal Pradesh', 'Mizoram']\n",
    "    }\n",
    "    \n",
    "    df['Region'] = df['State'].map({state: region for region, states in state_groups.items() for state in states})\n",
    "    return df\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164160f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b38cd1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    add_region_column(df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnwise null-count and duplicated_rows-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "384a7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_trans_df:\n",
      "Null count: \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "Transaction_type      0\n",
      "Transaction_count     0\n",
      "Transaction_amount    0\n",
      "Region                0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(3594, 7)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "agg_user_df:\n",
      "Null count: \n",
      "State                0\n",
      "Year                 0\n",
      "Quarter              0\n",
      "Brand                0\n",
      "Transaction_count    0\n",
      "Percentage           0\n",
      "Region               0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(6732, 7)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "map_trans_df:\n",
      "Null count: \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "District              0\n",
      "Transaction_count     0\n",
      "Transaction_amount    0\n",
      "Region                0\n",
      "Latitude_x            0\n",
      "Longitude_x           0\n",
      "Latitude_y            0\n",
      "Longitude_y           0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(14636, 11)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "map_user_df:\n",
      "Null count: \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "District            0\n",
      "Registered_users    0\n",
      "App_opens           0\n",
      "Region              0\n",
      "Latitude_x          0\n",
      "Longitude_x         0\n",
      "Latitude_y          0\n",
      "Longitude_y         0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(14640, 11)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_trans_dist_df:\n",
      "Null count: \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "District              0\n",
      "Transaction_count     0\n",
      "Transaction_amount    0\n",
      "Region                0\n",
      "Latitude_x            0\n",
      "Longitude_x           0\n",
      "Latitude_y            0\n",
      "Longitude_y           0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(5920, 11)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_trans_pin_df:\n",
      "Null count: \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "Pincode               0\n",
      "Transaction_count     0\n",
      "Transaction_amount    0\n",
      "Region                0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(7137, 7)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_user_dist_df:\n",
      "Null count: \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "District            0\n",
      "Registered_users    0\n",
      "Region              0\n",
      "Latitude_x          0\n",
      "Longitude_x         0\n",
      "Latitude_y          0\n",
      "Longitude_y         0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(5920, 10)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_user_pin_df:\n",
      "Null count: \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "Pincode             0\n",
      "Registered_users    0\n",
      "Region              0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(7140, 6)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "lat_long_df:\n",
      "Null count: \n",
      "State        0\n",
      "District     0\n",
      "Latitude     0\n",
      "Longitude    0\n",
      "Region       0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(732, 5)\n",
      "\n",
      " _________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(f\"{df_name}:\")\n",
    "    print(f\"Null count: \\n{df.isnull().sum()}\")\n",
    "    print(f\"Duplicated rows count: \\n{df.duplicated().sum()}\")\n",
    "    print(df.shape)\n",
    "    print(\"\\n\", 25 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "48f06489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME INFO:\n",
      "\n",
      "agg_trans_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3594 entries, 0 to 3593\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               3594 non-null   object \n",
      " 1   Year                3594 non-null   int32  \n",
      " 2   Quarter             3594 non-null   int64  \n",
      " 3   Transaction_type    3594 non-null   object \n",
      " 4   Transaction_count   3594 non-null   int64  \n",
      " 5   Transaction_amount  3594 non-null   float64\n",
      " 6   Region              3594 non-null   object \n",
      "dtypes: float64(1), int32(1), int64(2), object(3)\n",
      "memory usage: 182.6+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "agg_user_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6732 entries, 0 to 6731\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   State              6732 non-null   object \n",
      " 1   Year               6732 non-null   int32  \n",
      " 2   Quarter            6732 non-null   int64  \n",
      " 3   Brand              6732 non-null   object \n",
      " 4   Transaction_count  6732 non-null   int64  \n",
      " 5   Percentage         6732 non-null   float64\n",
      " 6   Region             6732 non-null   object \n",
      "dtypes: float64(1), int32(1), int64(2), object(3)\n",
      "memory usage: 342.0+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "map_trans_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14636 entries, 0 to 14635\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               14636 non-null  object \n",
      " 1   Year                14636 non-null  int32  \n",
      " 2   Quarter             14636 non-null  int64  \n",
      " 3   District            14636 non-null  object \n",
      " 4   Transaction_count   14636 non-null  int64  \n",
      " 5   Transaction_amount  14636 non-null  float64\n",
      " 6   Region              14636 non-null  object \n",
      " 7   Latitude_x          14636 non-null  float64\n",
      " 8   Longitude_x         14636 non-null  float64\n",
      " 9   Latitude_y          14636 non-null  float64\n",
      " 10  Longitude_y         14636 non-null  float64\n",
      "dtypes: float64(5), int32(1), int64(2), object(3)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "map_user_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   State             14640 non-null  object \n",
      " 1   Year              14640 non-null  int32  \n",
      " 2   Quarter           14640 non-null  int64  \n",
      " 3   District          14640 non-null  object \n",
      " 4   Registered_users  14640 non-null  int64  \n",
      " 5   App_opens         14640 non-null  int64  \n",
      " 6   Region            14640 non-null  object \n",
      " 7   Latitude_x        14640 non-null  float64\n",
      " 8   Longitude_x       14640 non-null  float64\n",
      " 9   Latitude_y        14640 non-null  float64\n",
      " 10  Longitude_y       14640 non-null  float64\n",
      "dtypes: float64(4), int32(1), int64(3), object(3)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_trans_dist_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5920 entries, 0 to 5919\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               5920 non-null   object \n",
      " 1   Year                5920 non-null   int32  \n",
      " 2   Quarter             5920 non-null   int64  \n",
      " 3   District            5920 non-null   object \n",
      " 4   Transaction_count   5920 non-null   int64  \n",
      " 5   Transaction_amount  5920 non-null   float64\n",
      " 6   Region              5920 non-null   object \n",
      " 7   Latitude_x          5920 non-null   float64\n",
      " 8   Longitude_x         5920 non-null   float64\n",
      " 9   Latitude_y          5920 non-null   float64\n",
      " 10  Longitude_y         5920 non-null   float64\n",
      "dtypes: float64(5), int32(1), int64(2), object(3)\n",
      "memory usage: 485.8+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_trans_pin_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7137 entries, 0 to 7138\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               7137 non-null   object \n",
      " 1   Year                7137 non-null   int32  \n",
      " 2   Quarter             7137 non-null   int64  \n",
      " 3   Pincode             7137 non-null   object \n",
      " 4   Transaction_count   7137 non-null   int64  \n",
      " 5   Transaction_amount  7137 non-null   float64\n",
      " 6   Region              7137 non-null   object \n",
      "dtypes: float64(1), int32(1), int64(2), object(3)\n",
      "memory usage: 418.2+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_user_dist_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5920 entries, 0 to 5919\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   State             5920 non-null   object \n",
      " 1   Year              5920 non-null   int32  \n",
      " 2   Quarter           5920 non-null   int64  \n",
      " 3   District          5920 non-null   object \n",
      " 4   Registered_users  5920 non-null   int64  \n",
      " 5   Region            5920 non-null   object \n",
      " 6   Latitude_x        5920 non-null   float64\n",
      " 7   Longitude_x       5920 non-null   float64\n",
      " 8   Latitude_y        5920 non-null   float64\n",
      " 9   Longitude_y       5920 non-null   float64\n",
      "dtypes: float64(4), int32(1), int64(2), object(3)\n",
      "memory usage: 439.5+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_user_pin_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7140 entries, 0 to 7139\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   State             7140 non-null   object\n",
      " 1   Year              7140 non-null   int32 \n",
      " 2   Quarter           7140 non-null   int64 \n",
      " 3   Pincode           7140 non-null   object\n",
      " 4   Registered_users  7140 non-null   int64 \n",
      " 5   Region            7140 non-null   object\n",
      "dtypes: int32(1), int64(2), object(3)\n",
      "memory usage: 306.9+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "lat_long_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 732 entries, 0 to 731\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   State      732 non-null    object \n",
      " 1   District   732 non-null    object \n",
      " 2   Latitude   732 non-null    float64\n",
      " 3   Longitude  732 non-null    float64\n",
      " 4   Region     732 non-null    object \n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 28.7+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('DATAFRAME INFO:\\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(df_name + ':\\n')\n",
    "    df.info()\n",
    "    print(\"\\n\", 45 * \"_\", \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac1c47d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                 0\n",
       "Year                  0\n",
       "Quarter               0\n",
       "Pincode               0\n",
       "Transaction_count     0\n",
       "Transaction_amount    0\n",
       "Region                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'top_trans_pin_df' seems to have two null values and they are not of significant proportion so dropping them;\n",
    "\n",
    "top_trans_pin_df.dropna(axis = 'index', inplace = True)\n",
    "top_trans_pin_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing datatype across all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44cdd537",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df_name \u001b[38;5;129;01min\u001b[39;00m df_list:\n\u001b[0;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[df_name]\n\u001b[1;32m----> 4\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "# Year column in all the dataframes seems to be of object dtype so changing it to int object so as to push into MySQL as year;\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    df['Year'] = df['Year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier count across all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16424d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything seems to be alright as far as dtypes and nullvalues are concerned so checking for outliers\n",
    "# Function to check for outliers\n",
    "\n",
    "def count_outliers(df):\n",
    "    outliers = {}\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        if col in ['Transaction_count', 'Transaction_amount']:\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            upper_bound = q3 + (1.5 * iqr)\n",
    "            lower_bound = q1 - (1.5 * iqr)\n",
    "            outliers[col] = len(df[(df[col] > upper_bound) | (df[col] < lower_bound)])\n",
    "        else:\n",
    "            continue\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3eaecf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTLIER COUNT ACROSS DATAFRAMES:\n",
      "\n",
      "agg_trans_df :\n",
      "\n",
      " {'Transaction_count': 652, 'Transaction_amount': 660} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "agg_user_df :\n",
      "\n",
      " {'Transaction_count': 893} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "map_trans_df :\n",
      "\n",
      " {'Transaction_count': 1811, 'Transaction_amount': 1771} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_dist_df :\n",
      "\n",
      " {'Transaction_count': 734, 'Transaction_amount': 743} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_pin_df :\n",
      "\n",
      " {'Transaction_count': 999, 'Transaction_amount': 995} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('OUTLIER COUNT ACROSS DATAFRAMES:\\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    outliers = count_outliers(df)\n",
    "    if len(outliers) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        print(df_name, \":\\n\\n\", outliers, \"\\n\")\n",
    "        print(\"\\n\", 55 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88ffbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique value count across all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56360e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for unique value counts and print if count less than 10;\n",
    "\n",
    "def unique_value_count(df, exclude_cols=[]):\n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        unique_vals = df[col].nunique()\n",
    "        print(f\"{col}: {unique_vals} unique values\")\n",
    "        if unique_vals < 10:\n",
    "            print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09752b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE VALUE COUNT ACROSS DATAFRAMES; \n",
      "\n",
      "agg_trans_df :\n",
      "\n",
      "Transaction_type: 5 unique values\n",
      "['Recharge & bill payments' 'Peer-to-peer payments' 'Merchant payments'\n",
      " 'Financial Services' 'Others']\n",
      "Transaction_count: 3548 unique values\n",
      "Transaction_amount: 3594 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "agg_user_df :\n",
      "\n",
      "Brand: 20 unique values\n",
      "Transaction_count: 6501 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "map_trans_df :\n",
      "\n",
      "District: 727 unique values\n",
      "Transaction_count: 14566 unique values\n",
      "Transaction_amount: 14636 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "Latitude_x: 533 unique values\n",
      "Longitude_x: 540 unique values\n",
      "Latitude_y: 533 unique values\n",
      "Longitude_y: 540 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "map_user_df :\n",
      "\n",
      "District: 727 unique values\n",
      "Registered_users: 14351 unique values\n",
      "App_opens: 10977 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "Latitude_x: 533 unique values\n",
      "Longitude_x: 540 unique values\n",
      "Latitude_y: 533 unique values\n",
      "Longitude_y: 540 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_dist_df :\n",
      "\n",
      "District: 368 unique values\n",
      "Transaction_count: 5910 unique values\n",
      "Transaction_amount: 5920 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "Latitude_x: 300 unique values\n",
      "Longitude_x: 299 unique values\n",
      "Latitude_y: 300 unique values\n",
      "Longitude_y: 299 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_pin_df :\n",
      "\n",
      "Pincode: 746 unique values\n",
      "Transaction_count: 7083 unique values\n",
      "Transaction_amount: 7137 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_user_dist_df :\n",
      "\n",
      "District: 313 unique values\n",
      "Registered_users: 5874 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "Latitude_x: 258 unique values\n",
      "Longitude_x: 258 unique values\n",
      "Latitude_y: 258 unique values\n",
      "Longitude_y: 258 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_user_pin_df :\n",
      "\n",
      "Pincode: 426 unique values\n",
      "Registered_users: 6882 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "lat_long_df :\n",
      "\n",
      "District: 727 unique values\n",
      "Latitude: 533 unique values\n",
      "Longitude: 540 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('UNIQUE VALUE COUNT ACROSS DATAFRAMES; \\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(df_name, \":\\n\")\n",
    "    unique_value_count(df, exclude_cols = ['State', 'Year', 'Quarter', 'Percentage'])\n",
    "    print(\"\\n\", 55 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Though outliers haven't gave much of an insight, unique value count can be used to gain some good insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09cb35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dfs_as_csv(df_list):\n",
    "    subfolder = 'Miscellaneous'\n",
    "    if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "        \n",
    "    for df_name in df_list:\n",
    "        df = globals()[df_name]\n",
    "        file_path = os.path.join(subfolder, df_name.replace('_df', '') + '.csv')\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "# Calling function to execute\n",
    "\n",
    "save_dfs_as_csv(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9679e7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agg_trans_df',\n",
       " 'agg_user_df',\n",
       " 'map_trans_df',\n",
       " 'map_user_df',\n",
       " 'top_trans_dist_df',\n",
       " 'top_trans_pin_df',\n",
       " 'top_user_dist_df',\n",
       " 'top_user_pin_df',\n",
       " 'lat_long_df']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f852de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2760b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establishing connection and creating cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "117e1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(\n",
    "  host = \"localhost\",\n",
    "  user = \"root\",\n",
    "  password = \"Samuel@151299\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7e2ee8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor.execute(\"DROP DATABASE IF EXISTS phonepe_pulse\")\n",
    "\n",
    "cursor.execute(\"CREATE DATABASE phonepe_pulse\")\n",
    "\n",
    "cursor.execute(\"USE phonepe_pulse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a563faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating tables\n",
    "State\tYear\tQuarter\tTransaction_type\tTransaction_count\tTransaction_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5f979d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''CREATE TABLE IF NOT EXISTS agg_trans (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Transaction_type VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Transaction_type(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS agg_user (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Brand VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Percentage FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Brand(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS map_trans (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,\n",
    "                    Latitude FLOAT,\n",
    "                    Longitude FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS map_user (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Registered_users INTEGER,\n",
    "                    App_opens INTEGER,\n",
    "                    Latitude FLOAT,\n",
    "                    Longitude FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS top_trans_dist (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,\n",
    "                    Latitude FLOAT,\n",
    "                    Longitude FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS top_trans_pin (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Pincode VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Pincode(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS top_user_dist (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Registered_users INTEGER,\n",
    "                    Latitude FLOAT,\n",
    "                    Longitude FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS top_user_pin (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Pincode VARCHAR(255),\n",
    "                    Registered_users INTEGER,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Pincode(255), Region(255))\n",
    "                 )''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pushing data into MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd651ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_data_into_mysql(conn, cursor, dfs, table_columns):\n",
    "    for table_name in dfs.keys():\n",
    "        df = dfs[table_name]\n",
    "        columns = table_columns[table_name]\n",
    "        placeholders = ', '.join(['%s'] * len(columns))\n",
    "        query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders})\"\n",
    "        for _, row in df.iterrows():\n",
    "            data = tuple(row[column] for column in columns)\n",
    "            cursor.execute(query, data)\n",
    "        conn.commit()\n",
    "    print(\"Data successfully pushed into MySQL tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8ffd0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping my_sql tables to pandas dataframes that we have created earlier\n",
    "\n",
    "dfs = {\n",
    "    'agg_trans': agg_trans_df,\n",
    "    'agg_user': agg_user_df,\n",
    "    'map_trans': map_trans_df,\n",
    "    'map_user': map_user_df,\n",
    "    'top_trans_dist': top_trans_dist_df,\n",
    "    'top_trans_pin': top_trans_pin_df,\n",
    "    'top_user_dist': top_user_dist_df,\n",
    "    'top_user_pin': top_user_pin_df\n",
    "}\n",
    "\n",
    "# Mapping table name to associated columns for each table\n",
    "\n",
    "table_columns = {\n",
    "    'agg_trans': list(agg_trans_df.columns),\n",
    "    'agg_user': list(agg_user_df.columns),\n",
    "    'map_trans': list(map_trans_df.columns),\n",
    "    'map_user': list(map_user_df.columns),\n",
    "    'top_trans_dist': list(top_trans_dist_df.columns),\n",
    "    'top_trans_pin': list(top_trans_pin_df.columns),\n",
    "    'top_user_dist': list(top_user_dist_df.columns),\n",
    "    'top_user_pin': list(top_user_pin_df.columns)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82836094",
   "metadata": {},
   "outputs": [],
   "source": [
    "push_data_into_mysql(conn, cursor, dfs, table_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f77bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5886d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_trans table has 3594 rows and 7 columns and shape matches DataFrame.\n",
      "agg_user table has 6732 rows and 7 columns and shape matches DataFrame.\n",
      "map_trans table has 0 rows and 9 columns but shape does not match DataFrame.\n",
      "map_user table has 0 rows and 9 columns but shape does not match DataFrame.\n",
      "top_trans_dist table has 0 rows and 9 columns but shape does not match DataFrame.\n",
      "top_trans_pin table has 0 rows and 7 columns but shape does not match DataFrame.\n",
      "top_user_dist table has 0 rows and 8 columns but shape does not match DataFrame.\n",
      "top_user_pin table has 0 rows and 6 columns but shape does not match DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Get list of tables in database\n",
    "\n",
    "cursor.execute(\"SHOW TABLES\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Loop through tables and get count of rows and columns in MySQL\n",
    "\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "    row_count = cursor.fetchone()[0]\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM information_schema.columns WHERE table_name='{table_name}'\")\n",
    "    column_count = cursor.fetchone()[0]\n",
    "\n",
    "    # Check if shape of DataFrame matches count of rows and columns in table\n",
    "\n",
    "    df = dfs[table_name]\n",
    "    if df.shape == (row_count, column_count):\n",
    "        print(f\"{table_name} table has {row_count} rows and {column_count} columns and shape matches DataFrame.\")\n",
    "    else:\n",
    "        print(f\"{table_name} table has {row_count} rows and {column_count} columns but shape does not match DataFrame.\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "41eb2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "344142f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit_extras\n",
      "  Downloading streamlit_extras-0.2.7-py3-none-any.whl (48 kB)\n",
      "                                              0.0/48.8 kB ? eta -:--:--\n",
      "     --------                                 10.2/48.8 kB ? eta -:--:--\n",
      "     -----------------------                30.7/48.8 kB 325.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 48.8/48.8 kB 308.4 kB/s eta 0:00:00\n",
      "Collecting htbuilder==0.6.1 (from streamlit_extras)\n",
      "  Downloading htbuilder-0.6.1.tar.gz (10 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting markdownlit>=0.0.5 (from streamlit_extras)\n",
      "  Downloading markdownlit-0.0.7-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit_extras) (3.20.3)\n",
      "Collecting st-annotated-text>=3.0.0 (from streamlit_extras)\n",
      "  Downloading st-annotated-text-4.0.0.tar.gz (7.8 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: streamlit>=1.0.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit_extras) (1.23.1)\n",
      "Collecting streamlit-camera-input-live>=0.2.0 (from streamlit_extras)\n",
      "  Downloading streamlit_camera_input_live-0.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting streamlit-card>=0.0.4 (from streamlit_extras)\n",
      "  Downloading streamlit_card-0.0.5-py3-none-any.whl (679 kB)\n",
      "                                              0.0/679.8 kB ? eta -:--:--\n",
      "     --                                       41.0/679.8 kB ? eta -:--:--\n",
      "     ---                                   61.4/679.8 kB 544.7 kB/s eta 0:00:02\n",
      "     --------                               153.6/679.8 kB 1.1 MB/s eta 0:00:01\n",
      "     --------                               153.6/679.8 kB 1.1 MB/s eta 0:00:01\n",
      "     ---------------                        276.5/679.8 kB 1.2 MB/s eta 0:00:01\n",
      "     ----------------                       286.7/679.8 kB 1.0 MB/s eta 0:00:01\n",
      "     ----------------------                 409.6/679.8 kB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------------            491.5/679.8 kB 1.3 MB/s eta 0:00:01\n",
      "     --------------------------------       573.4/679.8 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  675.8/679.8 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 679.8/679.8 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting streamlit-embedcode>=0.1.2 (from streamlit_extras)\n",
      "  Downloading streamlit_embedcode-0.1.2-py3-none-any.whl (3.5 kB)\n",
      "Collecting streamlit-faker>=0.0.2 (from streamlit_extras)\n",
      "  Downloading streamlit_faker-0.0.2-py3-none-any.whl (9.8 kB)\n",
      "Collecting streamlit-image-coordinates<0.2.0,>=0.1.1 (from streamlit_extras)\n",
      "  Downloading streamlit_image_coordinates-0.1.5-py3-none-any.whl (6.3 kB)\n",
      "Collecting streamlit-keyup>=0.1.9 (from streamlit_extras)\n",
      "  Downloading streamlit_keyup-0.2.0-py3-none-any.whl (7.4 kB)\n",
      "Collecting streamlit-toggle-switch>=1.0.2 (from streamlit_extras)\n",
      "  Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl (635 kB)\n",
      "                                              0.0/635.4 kB ? eta -:--:--\n",
      "     ------------                           204.8/635.4 kB 6.3 MB/s eta 0:00:01\n",
      "     ---------------                        256.0/635.4 kB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------                  358.4/635.4 kB 2.8 MB/s eta 0:00:01\n",
      "     ---------------------                  358.4/635.4 kB 2.8 MB/s eta 0:00:01\n",
      "     ----------------------------------     583.7/635.4 kB 2.6 MB/s eta 0:00:01\n",
      "     ----------------------------------     583.7/635.4 kB 2.6 MB/s eta 0:00:01\n",
      "     ----------------------------------     583.7/635.4 kB 2.6 MB/s eta 0:00:01\n",
      "     ----------------------------------     583.7/635.4 kB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 635.4/635.4 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting streamlit-vertical-slider>=1.0.2 (from streamlit_extras)\n",
      "  Downloading streamlit_vertical_slider-1.0.2-py3-none-any.whl (624 kB)\n",
      "                                              0.0/624.3 kB ? eta -:--:--\n",
      "     ----------                             174.1/624.3 kB 5.3 MB/s eta 0:00:01\n",
      "     ----------------                       276.5/624.3 kB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------               409.6/624.3 kB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------              419.8/624.3 kB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 624.3/624.3 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting more-itertools (from htbuilder==0.6.1->streamlit_extras)\n",
      "  Downloading more_itertools-9.1.0-py3-none-any.whl (54 kB)\n",
      "                                              0.0/54.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 54.2/54.2 kB ? eta 0:00:00\n",
      "Collecting markdown (from markdownlit>=0.0.5->streamlit_extras)\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "                                              0.0/93.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 93.9/93.9 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting lxml (from markdownlit>=0.0.5->streamlit_extras)\n",
      "  Downloading lxml-4.9.2-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "                                              0.0/3.8 MB ? eta -:--:--\n",
      "     -                                        0.2/3.8 MB 3.5 MB/s eta 0:00:02\n",
      "     --                                       0.3/3.8 MB 3.4 MB/s eta 0:00:02\n",
      "     ----                                     0.4/3.8 MB 3.1 MB/s eta 0:00:02\n",
      "     -----                                    0.6/3.8 MB 2.9 MB/s eta 0:00:02\n",
      "     -------                                  0.7/3.8 MB 3.0 MB/s eta 0:00:02\n",
      "     --------                                 0.8/3.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ----------                               1.0/3.8 MB 2.9 MB/s eta 0:00:01\n",
      "     -----------                              1.1/3.8 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------                            1.2/3.8 MB 2.9 MB/s eta 0:00:01\n",
      "     --------------                           1.4/3.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ----------------                         1.5/3.8 MB 3.0 MB/s eta 0:00:01\n",
      "     -------------------                      1.8/3.8 MB 3.2 MB/s eta 0:00:01\n",
      "     --------------------                     1.9/3.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ----------------------                   2.1/3.8 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------                 2.3/3.8 MB 3.3 MB/s eta 0:00:01\n",
      "     --------------------------               2.5/3.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------              2.6/3.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ----------------------------             2.6/3.8 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------          2.9/3.8 MB 3.3 MB/s eta 0:00:01\n",
      "     --------------------------------         3.0/3.8 MB 3.3 MB/s eta 0:00:01\n",
      "     ----------------------------------       3.2/3.8 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------------     3.5/3.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.7/3.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.8/3.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.8/3.8 MB 3.2 MB/s eta 0:00:00\n",
      "Collecting favicon (from markdownlit>=0.0.5->streamlit_extras)\n",
      "  Downloading favicon-0.7.0-py2.py3-none-any.whl (5.9 kB)\n",
      "Collecting pymdown-extensions (from markdownlit>=0.0.5->streamlit_extras)\n",
      "  Downloading pymdown_extensions-10.0.1-py3-none-any.whl (240 kB)\n",
      "                                              0.0/240.1 kB ? eta -:--:--\n",
      "     -------------------------------------  235.5/240.1 kB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 240.1/240.1 kB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (6.6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (1.24.3)\n",
      "Requirement already satisfied: packaging<24,>=14.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (2.0.2)\n",
      "Requirement already satisfied: pillow<10,>=6.2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (9.5.0)\n",
      "Requirement already satisfied: pyarrow>=4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (12.0.0)\n",
      "Requirement already satisfied: pympler<2,>=0.9 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.4 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (2.30.0)\n",
      "Requirement already satisfied: rich<14,>=10.11.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (13.4.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.0.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (8.2.2)\n",
      "Requirement already satisfied: toml<2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (4.6.3)\n",
      "Requirement already satisfied: tzlocal<5,>=1.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (4.3)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (0.20.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (3.1.31)\n",
      "Requirement already satisfied: pydeck<1,>=0.1.dev5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (6.3.1)\n",
      "Requirement already satisfied: watchdog in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=1.0.0->streamlit_extras) (3.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit-camera-input-live>=0.2.0->streamlit_extras) (3.1.2)\n",
      "Collecting faker (from streamlit-faker>=0.0.2->streamlit_extras)\n",
      "  Downloading Faker-18.11.1-py3-none-any.whl (1.7 MB)\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "     -----                                    0.2/1.7 MB 7.0 MB/s eta 0:00:01\n",
      "     ----------                               0.5/1.7 MB 5.8 MB/s eta 0:00:01\n",
      "     -----------------                        0.7/1.7 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------                    0.9/1.7 MB 3.9 MB/s eta 0:00:01\n",
      "     -------------------------                1.1/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------------         1.4/1.7 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------------     1.6/1.7 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit-faker>=0.0.2->streamlit_extras) (3.7.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit>=1.0.0->streamlit_extras) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit>=1.0.0->streamlit_extras) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit>=1.0.0->streamlit_extras) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3->streamlit>=1.0.0->streamlit_extras) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit>=1.0.0->streamlit_extras) (3.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=0.25->streamlit>=1.0.0->streamlit_extras) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=0.25->streamlit>=1.0.0->streamlit_extras) (2023.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->streamlit-camera-input-live>=0.2.0->streamlit_extras) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil<3,>=2->streamlit>=1.0.0->streamlit_extras) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=1.0.0->streamlit_extras) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=1.0.0->streamlit_extras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=1.0.0->streamlit_extras) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=1.0.0->streamlit_extras) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14,>=10.11.0->streamlit>=1.0.0->streamlit_extras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14,>=10.11.0->streamlit>=1.0.0->streamlit_extras) (2.15.1)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tzlocal<5,>=1.1->streamlit>=1.0.0->streamlit_extras) (0.1.0.post0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from validators<1,>=0.2->streamlit>=1.0.0->streamlit_extras) (5.1.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.7.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from favicon->markdownlit>=0.0.5->streamlit_extras) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit_extras) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit_extras) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit_extras) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit_extras) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit_extras) (3.0.9)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymdown-extensions->markdownlit>=0.0.5->streamlit_extras) (6.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4>=4.7.0->favicon->markdownlit>=0.0.5->streamlit_extras) (2.4.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit>=1.0.0->streamlit_extras) (5.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.0.0->streamlit_extras) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.0.0->streamlit_extras) (0.19.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.11.0->streamlit>=1.0.0->streamlit_extras) (0.1.2)\n",
      "Building wheels for collected packages: htbuilder, st-annotated-text\n",
      "  Building wheel for htbuilder (pyproject.toml): started\n",
      "  Building wheel for htbuilder (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for htbuilder: filename=htbuilder-0.6.1-py3-none-any.whl size=12483 sha256=7b4e7877726d9b3881d0925df2feacd7b233d9ff88148e73db657e835ca30765\n",
      "  Stored in directory: c:\\users\\morle\\appdata\\local\\pip\\cache\\wheels\\e2\\b3\\8b\\3178ccf0d59f158ee457e114026064d78b2c91bbf29f3d87b6\n",
      "  Building wheel for st-annotated-text (pyproject.toml): started\n",
      "  Building wheel for st-annotated-text (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for st-annotated-text: filename=st_annotated_text-4.0.0-py3-none-any.whl size=8924 sha256=e9fa4f7fe8b1b2187ab6174d07117131e6ac670a2f71bffd5a61221ff604fdee\n",
      "  Stored in directory: c:\\users\\morle\\appdata\\local\\pip\\cache\\wheels\\6b\\6a\\df\\1eda8d742a9094f5694398f5a81a4eb8297297b2cf9f027342\n",
      "Successfully built htbuilder st-annotated-text\n",
      "Installing collected packages: more-itertools, markdown, lxml, pymdown-extensions, htbuilder, favicon, faker, st-annotated-text, streamlit-vertical-slider, streamlit-toggle-switch, streamlit-keyup, streamlit-image-coordinates, streamlit-embedcode, streamlit-card, streamlit-camera-input-live, streamlit-faker, markdownlit, streamlit_extras\n",
      "Successfully installed faker-18.11.1 favicon-0.7.0 htbuilder-0.6.1 lxml-4.9.2 markdown-3.4.3 markdownlit-0.0.7 more-itertools-9.1.0 pymdown-extensions-10.0.1 st-annotated-text-4.0.0 streamlit-camera-input-live-0.2.0 streamlit-card-0.0.5 streamlit-embedcode-0.1.2 streamlit-faker-0.0.2 streamlit-image-coordinates-0.1.5 streamlit-keyup-0.2.0 streamlit-toggle-switch-1.0.2 streamlit-vertical-slider-1.0.2 streamlit_extras-0.2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit_extras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2bd88515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import json\n",
    "from streamlit_extras.add_vertical_space import add_vertical_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "99d3cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ydata_profilingNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached ydata_profiling-4.3.1-py2.py3-none-any.whl (352 kB)\n",
      "Collecting scipy<1.11,>=1.4.1 (from ydata_profiling)\n",
      "  Using cached scipy-1.10.1-cp311-cp311-win_amd64.whl (42.2 MB)\n",
      "Requirement already satisfied: pandas!=1.4.0,<2.1,>1.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (2.0.2)\n",
      "Requirement already satisfied: matplotlib<4,>=3.2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (3.7.1)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (1.10.9)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (6.0)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (3.1.2)\n",
      "Collecting visions[type_image_path]==0.7.5 (from ydata_profiling)\n",
      "  Using cached visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: numpy<1.24,>=1.16.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (1.23.5)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (0.1.12)\n",
      "Collecting phik<0.13,>=0.11.1 (from ydata_profiling)\n",
      "  Using cached phik-0.12.3-cp311-cp311-win_amd64.whl (663 kB)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (2.30.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (4.65.0)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (0.12.2)\n",
      "Collecting multimethod<2,>=1.4 (from ydata_profiling)\n",
      "  Using cached multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
      "Collecting statsmodels<1,>=0.13.2 (from ydata_profiling)\n",
      "  Using cached statsmodels-0.14.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "Requirement already satisfied: typeguard<3,>=2.13.2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ydata_profiling) (2.13.3)\n",
      "Collecting imagehash==4.3.1 (from ydata_profiling)\n",
      "  Using cached ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "Collecting wordcloud>=1.9.1 (from ydata_profiling)\n",
      "  Using cached wordcloud-1.9.2-cp311-cp311-win_amd64.whl (151 kB)\n",
      "Collecting dacite>=1.8 (from ydata_profiling)\n",
      "  Using cached dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Collecting PyWavelets (from imagehash==4.3.1->ydata_profiling)\n",
      "  Using cached PyWavelets-1.4.1-cp311-cp311-win_amd64.whl (4.2 MB)\n",
      "Requirement already satisfied: pillow in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imagehash==4.3.1->ydata_profiling) (9.5.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata_profiling) (23.1.0)\n",
      "Collecting networkx>=2.4 (from visions[type_image_path]==0.7.5->ydata_profiling)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata_profiling) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2<3.2,>=2.11.1->ydata_profiling) (2.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4,>=3.2->ydata_profiling) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4,>=3.2->ydata_profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4,>=3.2->ydata_profiling) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4,>=3.2->ydata_profiling) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4,>=3.2->ydata_profiling) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4,>=3.2->ydata_profiling) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4,>=3.2->ydata_profiling) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas!=1.4.0,<2.1,>1.1->ydata_profiling) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas!=1.4.0,<2.1,>1.1->ydata_profiling) (2023.3)\n",
      "Collecting joblib>=0.14.1 (from phik<0.13,>=0.11.1->ydata_profiling)\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2,>=1.8.1->ydata_profiling) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.24.0->ydata_profiling) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.24.0->ydata_profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.24.0->ydata_profiling) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.24.0->ydata_profiling) (2023.5.7)\n",
      "Collecting patsy>=0.5.2 (from statsmodels<1,>=0.13.2->ydata_profiling)\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<5,>=4.48.2->ydata_profiling) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata_profiling) (1.16.0)\n",
      "Installing collected packages: scipy, PyWavelets, patsy, networkx, multimethod, joblib, dacite, imagehash, wordcloud, visions, statsmodels, phik, ydata_profiling\n",
      "Successfully installed PyWavelets-1.4.1 dacite-1.8.1 imagehash-4.3.1 joblib-1.2.0 multimethod-1.9.1 networkx-3.1 patsy-0.5.3 phik-0.12.3 scipy-1.10.1 statsmodels-0.14.0 visions-0.7.5 wordcloud-1.9.2 ydata_profiling-4.3.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install  ydata_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3911e5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit_player\n",
      "  Downloading streamlit_player-0.1.5-py3-none-any.whl (1.7 MB)\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "     -                                        0.1/1.7 MB 254.2 kB/s eta 0:00:07\n",
      "     -                                        0.1/1.7 MB 254.2 kB/s eta 0:00:07\n",
      "     -                                        0.1/1.7 MB 254.2 kB/s eta 0:00:07\n",
      "     ---                                      0.1/1.7 MB 303.9 kB/s eta 0:00:06\n",
      "     ----                                     0.2/1.7 MB 389.1 kB/s eta 0:00:04\n",
      "     ----                                     0.2/1.7 MB 389.1 kB/s eta 0:00:04\n",
      "     ----                                     0.2/1.7 MB 389.1 kB/s eta 0:00:04\n",
      "     ----                                     0.2/1.7 MB 389.1 kB/s eta 0:00:04\n",
      "     ----                                     0.2/1.7 MB 389.1 kB/s eta 0:00:04\n",
      "     ----                                     0.2/1.7 MB 389.1 kB/s eta 0:00:04\n",
      "     ----                                     0.2/1.7 MB 389.1 kB/s eta 0:00:04\n",
      "     ----                                     0.2/1.7 MB 389.1 kB/s eta 0:00:04\n",
      "     ----                                     0.2/1.7 MB 389.1 kB/s eta 0:00:04\n",
      "     --------                                 0.4/1.7 MB 388.7 kB/s eta 0:00:04\n",
      "     ---------                                0.4/1.7 MB 425.8 kB/s eta 0:00:04\n",
      "     ---------                                0.4/1.7 MB 425.8 kB/s eta 0:00:04\n",
      "     ---------                                0.4/1.7 MB 425.8 kB/s eta 0:00:04\n",
      "     ----------                               0.5/1.7 MB 396.7 kB/s eta 0:00:04\n",
      "     -------------                            0.6/1.7 MB 502.6 kB/s eta 0:00:03\n",
      "     -------------                            0.6/1.7 MB 502.6 kB/s eta 0:00:03\n",
      "     -------------                            0.6/1.7 MB 502.6 kB/s eta 0:00:03\n",
      "     -------------                            0.6/1.7 MB 502.6 kB/s eta 0:00:03\n",
      "     ------------------                       0.8/1.7 MB 578.3 kB/s eta 0:00:02\n",
      "     ------------------                       0.8/1.7 MB 578.3 kB/s eta 0:00:02\n",
      "     ------------------                       0.8/1.7 MB 578.3 kB/s eta 0:00:02\n",
      "     ------------------                       0.8/1.7 MB 578.3 kB/s eta 0:00:02\n",
      "     ----------------------                   1.0/1.7 MB 614.9 kB/s eta 0:00:02\n",
      "     -----------------------                  1.0/1.7 MB 628.8 kB/s eta 0:00:02\n",
      "     -----------------------                  1.0/1.7 MB 628.8 kB/s eta 0:00:02\n",
      "     -----------------------                  1.0/1.7 MB 628.8 kB/s eta 0:00:02\n",
      "     ------------------------                 1.0/1.7 MB 589.7 kB/s eta 0:00:02\n",
      "     ----------------------------             1.2/1.7 MB 690.5 kB/s eta 0:00:01\n",
      "     ----------------------------             1.2/1.7 MB 690.5 kB/s eta 0:00:01\n",
      "     ----------------------------             1.2/1.7 MB 690.5 kB/s eta 0:00:01\n",
      "     ----------------------------             1.2/1.7 MB 690.5 kB/s eta 0:00:01\n",
      "     ---------------------------------        1.4/1.7 MB 723.6 kB/s eta 0:00:01\n",
      "     ---------------------------------        1.4/1.7 MB 728.1 kB/s eta 0:00:01\n",
      "     ----------------------------------       1.5/1.7 MB 710.6 kB/s eta 0:00:01\n",
      "     ------------------------------------     1.6/1.7 MB 743.3 kB/s eta 0:00:01\n",
      "     --------------------------------------   1.6/1.7 MB 761.4 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 777.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 772.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: streamlit>=0.73 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit_player) (1.23.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (6.6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (1.23.5)\n",
      "Requirement already satisfied: packaging<24,>=14.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (2.0.2)\n",
      "Requirement already satisfied: pillow<10,>=6.2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (9.5.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (12.0.0)\n",
      "Requirement already satisfied: pympler<2,>=0.9 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.4 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (2.30.0)\n",
      "Requirement already satisfied: rich<14,>=10.11.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (13.4.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.0.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (8.2.2)\n",
      "Requirement already satisfied: toml<2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (4.6.3)\n",
      "Requirement already satisfied: tzlocal<5,>=1.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (4.3)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (0.20.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (3.1.31)\n",
      "Requirement already satisfied: pydeck<1,>=0.1.dev5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (6.3.1)\n",
      "Requirement already satisfied: watchdog in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.73->streamlit_player) (3.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit>=0.73->streamlit_player) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit>=0.73->streamlit_player) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit>=0.73->streamlit_player) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit>=0.73->streamlit_player) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3->streamlit>=0.73->streamlit_player) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit>=0.73->streamlit_player) (3.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=0.25->streamlit>=0.73->streamlit_player) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=0.25->streamlit>=0.73->streamlit_player) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil<3,>=2->streamlit>=0.73->streamlit_player) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=0.73->streamlit_player) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=0.73->streamlit_player) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=0.73->streamlit_player) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=0.73->streamlit_player) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14,>=10.11.0->streamlit>=0.73->streamlit_player) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14,>=10.11.0->streamlit>=0.73->streamlit_player) (2.15.1)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tzlocal<5,>=1.1->streamlit>=0.73->streamlit_player) (0.1.0.post0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from validators<1,>=0.2->streamlit>=0.73->streamlit_player) (5.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit>=0.73->streamlit_player) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit>=0.73->streamlit_player) (2.1.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73->streamlit_player) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73->streamlit_player) (0.19.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.11.0->streamlit>=0.73->streamlit_player) (0.1.2)\n",
      "Installing collected packages: streamlit_player\n",
      "Successfully installed streamlit_player-0.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1b9b55c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit_pandas_profiling\n",
      "  Downloading streamlit_pandas_profiling-0.1.3-py3-none-any.whl (259 kB)\n",
      "                                              0.0/259.8 kB ? eta -:--:--\n",
      "                                              0.0/259.8 kB ? eta -:--:--\n",
      "                                              0.0/259.8 kB ? eta -:--:--\n",
      "                                              0.0/259.8 kB ? eta -:--:--\n",
      "                                              0.0/259.8 kB ? eta -:--:--\n",
      "                                              0.0/259.8 kB ? eta -:--:--\n",
      "                                              0.0/259.8 kB ? eta -:--:--\n",
      "     ----                                     30.7/259.8 kB ? eta -:--:--\n",
      "     ----                                     30.7/259.8 kB ? eta -:--:--\n",
      "     -----------                           81.9/259.8 kB 573.4 kB/s eta 0:00:01\n",
      "     -----------                           81.9/259.8 kB 573.4 kB/s eta 0:00:01\n",
      "     ---------------                      112.6/259.8 kB 504.4 kB/s eta 0:00:01\n",
      "     -----------------                    122.9/259.8 kB 425.1 kB/s eta 0:00:01\n",
      "     -----------------                    122.9/259.8 kB 425.1 kB/s eta 0:00:01\n",
      "     ----------------------------         204.8/259.8 kB 541.9 kB/s eta 0:00:01\n",
      "     ----------------------------         204.8/259.8 kB 541.9 kB/s eta 0:00:01\n",
      "     ----------------------------         204.8/259.8 kB 541.9 kB/s eta 0:00:01\n",
      "     ----------------------------         204.8/259.8 kB 541.9 kB/s eta 0:00:01\n",
      "     ----------------------------         204.8/259.8 kB 541.9 kB/s eta 0:00:01\n",
      "     ----------------------------         204.8/259.8 kB 541.9 kB/s eta 0:00:01\n",
      "     ----------------------------         204.8/259.8 kB 541.9 kB/s eta 0:00:01\n",
      "     ----------------------------         204.8/259.8 kB 541.9 kB/s eta 0:00:01\n",
      "     ----------------------------         204.8/259.8 kB 541.9 kB/s eta 0:00:01\n",
      "     ----------------------------         204.8/259.8 kB 541.9 kB/s eta 0:00:01\n",
      "     ------------------------------------ 259.8/259.8 kB 301.4 kB/s eta 0:00:00\n",
      "Collecting pandas-profiling (from streamlit_pandas_profiling)\n",
      "  Downloading pandas_profiling-3.2.0-py2.py3-none-any.whl (262 kB)\n",
      "                                              0.0/262.6 kB ? eta -:--:--\n",
      "                                              0.0/262.6 kB ? eta -:--:--\n",
      "     ---------                               61.4/262.6 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------                           92.2/262.6 kB 1.0 MB/s eta 0:00:01\n",
      "     --------------------                   143.4/262.6 kB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------------       225.3/262.6 kB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 262.6/262.6 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: streamlit>=0.63 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit_pandas_profiling) (1.23.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (6.6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (1.23.5)\n",
      "Requirement already satisfied: packaging<24,>=14.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (2.0.2)\n",
      "Requirement already satisfied: pillow<10,>=6.2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (9.5.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (12.0.0)\n",
      "Requirement already satisfied: pympler<2,>=0.9 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.4 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (2.30.0)\n",
      "Requirement already satisfied: rich<14,>=10.11.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (13.4.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.0.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (8.2.2)\n",
      "Requirement already satisfied: toml<2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (4.6.3)\n",
      "Requirement already satisfied: tzlocal<5,>=1.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (4.3)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (0.20.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (3.1.31)\n",
      "Requirement already satisfied: pydeck<1,>=0.1.dev5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (6.3.1)\n",
      "Requirement already satisfied: watchdog in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit>=0.63->streamlit_pandas_profiling) (3.0.0)\n",
      "Collecting joblib~=1.1.0 (from pandas-profiling->streamlit_pandas_profiling)\n",
      "  Downloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
      "                                              0.0/309.8 kB ? eta -:--:--\n",
      "     -----------                             92.2/309.8 kB 1.8 MB/s eta 0:00:01\n",
      "     --------------------                   163.8/309.8 kB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------            225.3/309.8 kB 1.5 MB/s eta 0:00:01\n",
      "     -----------------------------------    286.7/309.8 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 309.8/309.8 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (1.10.1)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (3.7.1)\n",
      "Requirement already satisfied: pydantic>=1.8.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (1.10.9)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (6.0)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.1.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (2.1.2)\n",
      "Collecting visions[type_image_path]==0.7.4 (from pandas-profiling->streamlit_pandas_profiling)\n",
      "  Downloading visions-0.7.4-py3-none-any.whl (102 kB)\n",
      "                                              0.0/102.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 102.4/102.4 kB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (0.1.12)\n",
      "Collecting missingno>=0.4.2 (from pandas-profiling->streamlit_pandas_profiling)\n",
      "  Downloading missingno-0.5.2-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: phik>=0.11.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (0.12.3)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (0.2.0)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (4.65.0)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (0.12.2)\n",
      "Requirement already satisfied: multimethod>=1.4 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-profiling->streamlit_pandas_profiling) (1.9.1)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling->streamlit_pandas_profiling) (23.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling->streamlit_pandas_profiling) (3.1)\n",
      "Requirement already satisfied: imagehash in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling->streamlit_pandas_profiling) (4.3.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_pandas_profiling) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_pandas_profiling) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit>=0.63->streamlit_pandas_profiling) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3->streamlit>=0.63->streamlit_pandas_profiling) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit_pandas_profiling) (3.15.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling->streamlit_pandas_profiling) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling->streamlit_pandas_profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling->streamlit_pandas_profiling) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling->streamlit_pandas_profiling) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling->streamlit_pandas_profiling) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=0.25->streamlit>=0.63->streamlit_pandas_profiling) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=0.25->streamlit>=0.63->streamlit_pandas_profiling) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil<3,>=2->streamlit>=0.63->streamlit_pandas_profiling) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=0.63->streamlit_pandas_profiling) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=0.63->streamlit_pandas_profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=0.63->streamlit_pandas_profiling) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.4->streamlit>=0.63->streamlit_pandas_profiling) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14,>=10.11.0->streamlit>=0.63->streamlit_pandas_profiling) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14,>=10.11.0->streamlit>=0.63->streamlit_pandas_profiling) (2.15.1)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tzlocal<5,>=1.1->streamlit>=0.63->streamlit_pandas_profiling) (0.1.0.post0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from validators<1,>=0.2->streamlit>=0.63->streamlit_pandas_profiling) (5.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit>=0.63->streamlit_pandas_profiling) (5.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_pandas_profiling) (0.19.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.11.0->streamlit>=0.63->streamlit_pandas_profiling) (0.1.2)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\morle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling->streamlit_pandas_profiling) (1.4.1)\n",
      "Installing collected packages: joblib, visions, missingno, pandas-profiling, streamlit_pandas_profiling\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.2.0\n",
      "    Uninstalling joblib-1.2.0:\n",
      "      Successfully uninstalled joblib-1.2.0\n",
      "  Attempting uninstall: visions\n",
      "    Found existing installation: visions 0.7.5\n",
      "    Uninstalling visions-0.7.5:\n",
      "      Successfully uninstalled visions-0.7.5\n",
      "Successfully installed joblib-1.1.1 missingno-0.5.2 pandas-profiling-3.2.0 streamlit_pandas_profiling-0.1.3 visions-0.7.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ydata-profiling 4.3.1 requires visions[type_image_path]==0.7.5, but you have visions 0.7.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit_pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3fecf46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import mysql.connector\n",
    "import ydata_profiling\n",
    "from streamlit_player import st_player\n",
    "from streamlit_pandas_profiling import st_profile_report\n",
    "from streamlit_extras.metric_cards import style_metric_cards\n",
    "from streamlit_extras.add_vertical_space import add_vertical_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([1, 2, 3], [4, 5, 6])\n",
    "\n",
    "st.pyplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f7d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103a739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a05ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d86e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaaa070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
