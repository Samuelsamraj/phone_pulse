{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c46d7-073b-4ecb-bd73-740e6150ba54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!git clone https://github.com/PhonePe/pulse.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd67c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c07cc38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\phonepe_2\\Pulse\\data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from git import Repo\n",
    "           \n",
    "repo_url = \"https://github.com/PhonePe/pulse.git\"\n",
    "clone_path = \"C:\\phonepe_2\"\n",
    "# = r\"C:\\docs\\Projects\\Phonepe_pulse\\Miscellaneous\"\n",
    "if not os.path.exists(clone_path):\n",
    "    os.makedirs(clone_path)\n",
    "\n",
    "repo_path = os.path.join(clone_path, os.path.basename(repo_url).split('.')[0].title())\n",
    "\n",
    "Repo.clone_from(repo_url, repo_path)\n",
    "\n",
    "directory = os.path.join(repo_path, 'data')\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483d4951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rename messy state names in a proper format\n",
    "\n",
    "def rename(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if 'state' in dirs:\n",
    "            state_dir = os.path.join(root, 'state')\n",
    "            for state_folder in os.listdir(state_dir):\n",
    "                # rename the state folder\n",
    "                old_path = os.path.join(state_dir, state_folder)\n",
    "                new_path = os.path.join(state_dir, state_folder.title().replace('-', ' ').replace('&', 'and'))\n",
    "                os.rename(old_path, new_path)\n",
    "    print(\"Renamed all sub-directories successfully\")\n",
    "                \n",
    "# Function to extract all paths that has sub-directory in the name of 'state'\n",
    "\n",
    "def extract_paths(directory):\n",
    "    path_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if os.path.basename(root) == 'state':\n",
    "            path_list.append(root.replace('\\\\', '/'))\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb34696-7158-4ebd-8b4e-3381d3a5dfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed all sub-directories successfully\n"
     ]
    }
   ],
   "source": [
    "rename(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d243d5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/phonepe_2/Pulse/data/aggregated/transaction/country/india/state',\n",
       " 'C:/phonepe_2/Pulse/data/aggregated/user/country/india/state',\n",
       " 'C:/phonepe_2/Pulse/data/map/transaction/hover/country/india/state',\n",
       " 'C:/phonepe_2/Pulse/data/map/user/hover/country/india/state',\n",
       " 'C:/phonepe_2/Pulse/data/top/transaction/country/india/state',\n",
       " 'C:/phonepe_2/Pulse/data/top/user/country/india/state']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_directories = extract_paths(directory)\n",
    "state_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd684707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/phonepe_2/Pulse/data/aggregated/transaction/country/india/state',\n",
       " 'C:/phonepe_2/Pulse/data/aggregated/user/country/india/state',\n",
       " 'C:/phonepe_2/Pulse/data/map/transaction/hover/country/india/state',\n",
       " 'C:/phonepe_2/Pulse/data/map/user/hover/country/india/state',\n",
       " 'C:/phonepe_2/Pulse/data/top/transaction/country/india/state',\n",
       " 'C:/phonepe_2/Pulse/data/top/user/country/india/state']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_directories = extract_paths(directory)\n",
    "state_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa134c30-eee0-438b-9323-111d7f2ee862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframes from cloned json files\n",
    "#1. Aggregate Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef5dbf4-d58c-40f8-aede-d5315e06c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[0]\n",
    "state_list = os.listdir(state_path)\n",
    "agg_trans_dict = {\n",
    "                  'State': [], 'Year': [], 'Quarter': [], 'Transaction_type': [],\n",
    "                  'Transaction_count': [], 'Transaction_amount': []\n",
    "                  }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for transaction_data in df['data']['transactionData']:\n",
    "                    \n",
    "                    type = transaction_data['name']\n",
    "                    count = transaction_data['paymentInstruments'][0]['count']\n",
    "                    amount = transaction_data['paymentInstruments'][0]['amount']\n",
    "                    \n",
    "                    # Appending to agg_trans_dict\n",
    "                    \n",
    "                    agg_trans_dict['State'].append(state)\n",
    "                    agg_trans_dict['Year'].append(year)\n",
    "                    agg_trans_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    agg_trans_dict['Transaction_type'].append(type)\n",
    "                    agg_trans_dict['Transaction_count'].append(count)\n",
    "                    agg_trans_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "agg_trans_df = pd.DataFrame(agg_trans_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "52d966dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3de0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c03d18-fcd8-4203-83c3-e9f0566c6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aggregate User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe022c8-1405-4fb2-bd7c-7b8f368c7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[1]\n",
    "state_list = os.listdir(state_path)\n",
    "agg_user_dict = {\n",
    "                 'State': [], 'Year': [], 'Quarter': [], 'Brand': [],\n",
    "                 'Transaction_count': [], 'Percentage': []\n",
    "                 }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for user_data in df['data']['usersByDevice']:\n",
    "\n",
    "                    brand = user_data['brand']\n",
    "                    count = user_data['count']\n",
    "                    percent = user_data['percentage']\n",
    "                    \n",
    "                    # Appending to agg_user_dict\n",
    "                    \n",
    "                    agg_user_dict['State'].append(state)\n",
    "                    agg_user_dict['Year'].append(year)\n",
    "                    agg_user_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    agg_user_dict['Brand'].append(brand)\n",
    "                    agg_user_dict['Transaction_count'].append(count)\n",
    "                    agg_user_dict['Percentage'].append(percent)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "agg_user_df = pd.DataFrame(agg_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b20b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Map Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21075e2c-0af0-4fc9-9ccc-3d4b47ab6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[2]\n",
    "state_list = os.listdir(state_path)\n",
    "map_trans_dict = {\n",
    "                    'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                    'Transaction_count': [], 'Transaction_amount': []\n",
    "                    }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for transaction_data in df['data']['hoverDataList']:\n",
    "                   \n",
    "                    district = transaction_data['name']\n",
    "                    count = transaction_data['metric'][0]['count']\n",
    "                    amount = transaction_data['metric'][0]['amount']\n",
    "                    \n",
    "                    # Appending to map_trans_dict\n",
    "                    \n",
    "                    map_trans_dict['State'].append(state)\n",
    "                    map_trans_dict['Year'].append(year)\n",
    "                    map_trans_dict['Quarter'].append(int(quarter.removesuffix('.json'))) \n",
    "                    map_trans_dict['District'].append(district.removesuffix(' district').title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    map_trans_dict['Transaction_count'].append(count)\n",
    "                    map_trans_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_trans_df = pd.DataFrame(map_trans_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e7efa16-8131-42b0-ab69-fdbe85c4c9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>District</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>North and Middle Andaman</td>\n",
       "      <td>442</td>\n",
       "      <td>9.316631e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>South Andaman</td>\n",
       "      <td>5688</td>\n",
       "      <td>1.256025e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Nicobars</td>\n",
       "      <td>528</td>\n",
       "      <td>1.139849e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>North and Middle Andaman</td>\n",
       "      <td>825</td>\n",
       "      <td>1.317863e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>South Andaman</td>\n",
       "      <td>9395</td>\n",
       "      <td>2.394824e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Nadia</td>\n",
       "      <td>12690126</td>\n",
       "      <td>2.804568e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14632</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Birbhum</td>\n",
       "      <td>7617444</td>\n",
       "      <td>1.614650e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Purba Medinipur</td>\n",
       "      <td>14484229</td>\n",
       "      <td>3.309949e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Maldah</td>\n",
       "      <td>12492746</td>\n",
       "      <td>2.721861e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Darjiling</td>\n",
       "      <td>8827502</td>\n",
       "      <td>1.801650e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14636 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             State  Year  Quarter                  District  \\\n",
       "0      Andaman and Nicobar Islands  2018        1  North and Middle Andaman   \n",
       "1      Andaman and Nicobar Islands  2018        1             South Andaman   \n",
       "2      Andaman and Nicobar Islands  2018        1                  Nicobars   \n",
       "3      Andaman and Nicobar Islands  2018        2  North and Middle Andaman   \n",
       "4      Andaman and Nicobar Islands  2018        2             South Andaman   \n",
       "...                            ...   ...      ...                       ...   \n",
       "14631                  West Bengal  2022        4                     Nadia   \n",
       "14632                  West Bengal  2022        4                   Birbhum   \n",
       "14633                  West Bengal  2022        4           Purba Medinipur   \n",
       "14634                  West Bengal  2022        4                    Maldah   \n",
       "14635                  West Bengal  2022        4                 Darjiling   \n",
       "\n",
       "       Transaction_count  Transaction_amount  \n",
       "0                    442        9.316631e+05  \n",
       "1                   5688        1.256025e+07  \n",
       "2                    528        1.139849e+06  \n",
       "3                    825        1.317863e+06  \n",
       "4                   9395        2.394824e+07  \n",
       "...                  ...                 ...  \n",
       "14631           12690126        2.804568e+10  \n",
       "14632            7617444        1.614650e+10  \n",
       "14633           14484229        3.309949e+10  \n",
       "14634           12492746        2.721861e+10  \n",
       "14635            8827502        1.801650e+10  \n",
       "\n",
       "[14636 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9988ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Map User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "723726f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_path = state_directories[3]\n",
    "state_list = os.listdir(state_path)\n",
    "map_user_dict = {\n",
    "                 'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                 'Registered_users': [], 'App_opens': []\n",
    "                 }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district, user_data in df['data']['hoverData'].items():\n",
    "                    \n",
    "                    reg_user_count = user_data['registeredUsers']\n",
    "                    app_open_count = user_data['appOpens']\n",
    "                    \n",
    "                    # Appending to map_user_dict\n",
    "                    \n",
    "                    map_user_dict['State'].append(state)\n",
    "                    map_user_dict['Year'].append(year)\n",
    "                    map_user_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    map_user_dict['District'].append(district.removesuffix(' district').title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    map_user_dict['Registered_users'].append(reg_user_count)\n",
    "                    map_user_dict['App_opens'].append(app_open_count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_user_df = pd.DataFrame(map_user_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0561905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Top Transaction District-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9280a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[4]\n",
    "state_list = os.listdir(state_path)\n",
    "top_trans_dist_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                        'Transaction_count': [], 'Transaction_amount': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district_data in df['data']['districts']:\n",
    "                    \n",
    "                    name = district_data['entityName']\n",
    "                    count = district_data['metric']['count']\n",
    "                    amount = district_data['metric']['amount']\n",
    "                    \n",
    "                    # Appending to top_trans_dist_dict\n",
    "                    \n",
    "                    top_trans_dist_dict['State'].append(state)\n",
    "                    top_trans_dist_dict['Year'].append(year)\n",
    "                    top_trans_dist_dict['Quarter'].append(int(quarter.removesuffix('.json')))                    \n",
    "                    top_trans_dist_dict['District'].append(name.title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    top_trans_dist_dict['Transaction_count'].append(count)\n",
    "                    top_trans_dist_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_trans_dist_df = pd.DataFrame(top_trans_dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "88ef8501",
   "metadata": {},
   "outputs": [],
   "source": [
    " #6. Top Transaction Pincode-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "382d2183",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[4]\n",
    "state_list = os.listdir(state_path)\n",
    "top_trans_pin_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [], 'Pincode': [],\n",
    "                        'Transaction_count': [], 'Transaction_amount': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for regional_data in df['data']['pincodes']:\n",
    "                    \n",
    "                    name = regional_data['entityName']\n",
    "                    count = regional_data['metric']['count']\n",
    "                    amount = regional_data['metric']['amount']\n",
    "                    \n",
    "                    # Appending to top_trans_pin_dict\n",
    "                    \n",
    "                    top_trans_pin_dict['State'].append(state)\n",
    "                    top_trans_pin_dict['Year'].append(year)\n",
    "                    top_trans_pin_dict['Quarter'].append(int(quarter.removesuffix('.json')))                    \n",
    "                    top_trans_pin_dict['Pincode'].append(name)\n",
    "                    top_trans_pin_dict['Transaction_count'].append(count)\n",
    "                    top_trans_pin_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_trans_pin_df = pd.DataFrame(top_trans_pin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c646f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Top User District-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eb69a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[5]\n",
    "state_list = os.listdir(state_path)\n",
    "top_user_dist_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [],\n",
    "                        'District': [], 'Registered_users': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district_data in df['data']['districts']:\n",
    "                    \n",
    "                    name = district_data['name']\n",
    "                    count = district_data['registeredUsers']\n",
    "                    \n",
    "                    # Appending to top_user_dist_dict\n",
    "                    \n",
    "                    top_user_dist_dict['State'].append(state)\n",
    "                    top_user_dist_dict['Year'].append(year)\n",
    "                    top_user_dist_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    top_user_dist_dict['District'].append(name.title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    top_user_dist_dict['Registered_users'].append(count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_user_dist_df = pd.DataFrame(top_user_dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b0de09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Top User Pincode-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e9603fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[5]\n",
    "state_list = os.listdir(state_path)\n",
    "top_user_pin_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [],\n",
    "                        'Pincode': [], 'Registered_users': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for regional_data in df['data']['pincodes']:\n",
    "                    \n",
    "                    name = regional_data['name']\n",
    "                    count = regional_data['registeredUsers']\n",
    "                    \n",
    "                    # Appending to top_user_pin_dict\n",
    "                    \n",
    "                    top_user_pin_dict['State'].append(state)\n",
    "                    top_user_pin_dict['Year'].append(year)\n",
    "                    top_user_pin_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    top_user_pin_dict['Pincode'].append(name)\n",
    "                    top_user_pin_dict['Registered_users'].append(count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_user_pin_df = pd.DataFrame(top_user_pin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc166d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of dataframes created so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ac05ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agg_user_df',\n",
       " 'map_trans_df',\n",
       " 'map_user_df',\n",
       " 'top_trans_pin_df',\n",
       " 'top_user_dist_df',\n",
       " 'top_user_pin_df']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [df for df in globals() if isinstance(globals()[df], pd.core.frame.DataFrame) and df.endswith('_df')]\n",
    "\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4626f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming Delhi districts to manage inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc82931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As I noticed few district name is mismatched between dfs loaded from pulse and lat_long_df, doing this.\n",
    "\n",
    "def add_suffix_to_districts(df):\n",
    "    if 'District' in df.columns and 'State' in df.columns:\n",
    "        delhi_df = df[df['State'] == 'Delhi']\n",
    "        \n",
    "        districts_to_suffix = [d for d in delhi_df['District'].unique() if d != 'Shahdara']\n",
    "        \n",
    "        df.loc[(df['State'] == 'Delhi') & (df['District'].isin(districts_to_suffix)), 'District'] = df.loc[(df['State'] == 'Delhi') & (df['District'].isin(districts_to_suffix)), 'District'].apply(lambda x: x + ' Delhi' if 'Delhi' not in x else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    add_suffix_to_districts(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Latitude and Longitude columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d69ea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['State', 'Year', 'Quarter', 'District', 'Transaction_count',\n",
      "       'Transaction_amount', 'Latitude', 'Longitude'],\n",
      "      dtype='object')\n",
      "Index(['State', 'Year', 'Quarter', 'District', 'Registered_users', 'App_opens',\n",
      "       'Latitude', 'Longitude'],\n",
      "      dtype='object')\n",
      "Index(['State', 'Year', 'Quarter', 'District', 'Transaction_count',\n",
      "       'Transaction_amount', 'Latitude', 'Longitude'],\n",
      "      dtype='object')\n",
      "Index(['State', 'Year', 'Quarter', 'District', 'Registered_users', 'Latitude',\n",
      "       'Longitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lat_long_df = pd.read_csv(\"C:\\phone pe\\Phonepe_Pulse\\Miscellaneous\\dist_lat_long.csv\")\n",
    "#lat_long_df = lat_long_df.rename(columns={'Latitude': 'Latitude_y', 'Longitude': 'Longitude_y'})\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    if 'District' in df.columns:\n",
    "        df = pd.merge(df, lat_long_df, on=['State', 'District'], how='left')\n",
    "        \n",
    "        if 'Latitude_y' in df.columns and 'Longitude_y' in df.columns:\n",
    "            df = df.drop(['Latitude_y', 'Longitude_y'], axis=1)\n",
    "            \n",
    "        df = df.rename(columns={'Latitude_x': 'Latitude', 'Longitude_x': 'Longitude'})\n",
    "        print(df.columns)\n",
    "        globals()[df_name] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b77b0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_region_column(df):\n",
    "    state_groups = {\n",
    "        'Northern Region': ['Jammu and Kashmir', 'Himachal Pradesh', 'Punjab', 'Chandigarh', 'Uttarakhand', 'Ladakh', 'Delhi', 'Haryana'],\n",
    "        'Central Region': ['Uttar Pradesh', 'Madhya Pradesh', 'Chhattisgarh'],\n",
    "        'Western Region': ['Rajasthan', 'Gujarat', 'Dadra and Nagar Haveli and Daman and Diu', 'Maharashtra'],\n",
    "        'Eastern Region': ['Bihar', 'Jharkhand', 'Odisha', 'West Bengal', 'Sikkim'],\n",
    "        'Southern Region': ['Andhra Pradesh', 'Telangana', 'Karnataka', 'Kerala', 'Tamil Nadu', 'Puducherry', 'Goa', 'Lakshadweep', 'Andaman and Nicobar Islands'],\n",
    "        'North-Eastern Region': ['Assam', 'Meghalaya', 'Manipur', 'Nagaland', 'Tripura', 'Arunachal Pradesh', 'Mizoram']\n",
    "    }\n",
    "    \n",
    "    df['Region'] = df['State'].map({state: region for region, states in state_groups.items() for state in states})\n",
    "    return df\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9c7ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    add_region_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef5f55e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agg_user_df',\n",
       " 'map_trans_df',\n",
       " 'map_user_df',\n",
       " 'top_trans_pin_df',\n",
       " 'top_user_dist_df',\n",
       " 'top_user_pin_df',\n",
       " 'lat_long_df']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_list = [df for df in globals() if isinstance(globals()[df], pd.core.frame.DataFrame) and df.endswith('_df')]\n",
    "\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "164160f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>District</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>North and Middle Andaman</td>\n",
       "      <td>11.554828</td>\n",
       "      <td>92.238490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>South Andaman</td>\n",
       "      <td>10.705690</td>\n",
       "      <td>92.487468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>Nicobars</td>\n",
       "      <td>10.705690</td>\n",
       "      <td>92.487468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>East Godavari</td>\n",
       "      <td>17.233496</td>\n",
       "      <td>81.722599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Srikakulam</td>\n",
       "      <td>17.233496</td>\n",
       "      <td>81.722599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         State                  District   Latitude  Longitude\n",
       "0  Andaman and Nicobar Islands  North and Middle Andaman  11.554828  92.238490\n",
       "1  Andaman and Nicobar Islands             South Andaman  10.705690  92.487468\n",
       "2  Andaman and Nicobar Islands                  Nicobars  10.705690  92.487468\n",
       "3               Andhra Pradesh             East Godavari  17.233496  81.722599\n",
       "4               Andhra Pradesh                Srikakulam  17.233496  81.722599"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_long_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b38cd1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnwise null-count and duplicated_rows-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "384a7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_user_df:\n",
      "Null count: \n",
      "State                0\n",
      "Year                 0\n",
      "Quarter              0\n",
      "Brand                0\n",
      "Transaction_count    0\n",
      "Percentage           0\n",
      "Region               0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(6732, 7)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "map_trans_df:\n",
      "Null count: \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "District              0\n",
      "Transaction_count     0\n",
      "Transaction_amount    0\n",
      "Region                0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(14636, 7)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "map_user_df:\n",
      "Null count: \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "District            0\n",
      "Registered_users    0\n",
      "App_opens           0\n",
      "Region              0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(14640, 7)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_trans_pin_df:\n",
      "Null count: \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "Pincode               2\n",
      "Transaction_count     0\n",
      "Transaction_amount    0\n",
      "Region                0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(7139, 7)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_user_dist_df:\n",
      "Null count: \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "District            0\n",
      "Registered_users    0\n",
      "Region              0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(5920, 6)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_user_pin_df:\n",
      "Null count: \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "Pincode             0\n",
      "Registered_users    0\n",
      "Region              0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(7140, 6)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "lat_long_df:\n",
      "Null count: \n",
      "State        0\n",
      "District     0\n",
      "Latitude     0\n",
      "Longitude    0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(732, 4)\n",
      "\n",
      " _________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(f\"{df_name}:\")\n",
    "    print(f\"Null count: \\n{df.isnull().sum()}\")\n",
    "    print(f\"Duplicated rows count: \\n{df.duplicated().sum()}\")\n",
    "    print(df.shape)\n",
    "    print(\"\\n\", 25 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48f06489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME INFO:\n",
      "\n",
      "agg_user_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6732 entries, 0 to 6731\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   State              6732 non-null   object \n",
      " 1   Year               6732 non-null   object \n",
      " 2   Quarter            6732 non-null   int64  \n",
      " 3   Brand              6732 non-null   object \n",
      " 4   Transaction_count  6732 non-null   int64  \n",
      " 5   Percentage         6732 non-null   float64\n",
      " 6   Region             6732 non-null   object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 368.3+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "map_trans_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14636 entries, 0 to 14635\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               14636 non-null  object \n",
      " 1   Year                14636 non-null  object \n",
      " 2   Quarter             14636 non-null  int64  \n",
      " 3   District            14636 non-null  object \n",
      " 4   Transaction_count   14636 non-null  int64  \n",
      " 5   Transaction_amount  14636 non-null  float64\n",
      " 6   Region              14636 non-null  object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 800.5+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "map_user_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   State             14640 non-null  object\n",
      " 1   Year              14640 non-null  object\n",
      " 2   Quarter           14640 non-null  int64 \n",
      " 3   District          14640 non-null  object\n",
      " 4   Registered_users  14640 non-null  int64 \n",
      " 5   App_opens         14640 non-null  int64 \n",
      " 6   Region            14640 non-null  object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 800.8+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_trans_pin_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7139 entries, 0 to 7138\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               7139 non-null   object \n",
      " 1   Year                7139 non-null   object \n",
      " 2   Quarter             7139 non-null   int64  \n",
      " 3   Pincode             7137 non-null   object \n",
      " 4   Transaction_count   7139 non-null   int64  \n",
      " 5   Transaction_amount  7139 non-null   float64\n",
      " 6   Region              7139 non-null   object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 390.5+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_user_dist_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5920 entries, 0 to 5919\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   State             5920 non-null   object\n",
      " 1   Year              5920 non-null   object\n",
      " 2   Quarter           5920 non-null   int64 \n",
      " 3   District          5920 non-null   object\n",
      " 4   Registered_users  5920 non-null   int64 \n",
      " 5   Region            5920 non-null   object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 277.6+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_user_pin_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7140 entries, 0 to 7139\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   State             7140 non-null   object\n",
      " 1   Year              7140 non-null   object\n",
      " 2   Quarter           7140 non-null   int64 \n",
      " 3   Pincode           7140 non-null   object\n",
      " 4   Registered_users  7140 non-null   int64 \n",
      " 5   Region            7140 non-null   object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 334.8+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "lat_long_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 732 entries, 0 to 731\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   State      732 non-null    object \n",
      " 1   District   732 non-null    object \n",
      " 2   Latitude   732 non-null    float64\n",
      " 3   Longitude  732 non-null    float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 23.0+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('DATAFRAME INFO:\\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(df_name + ':\\n')\n",
    "    df.info()\n",
    "    print(\"\\n\", 45 * \"_\", \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac1c47d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                 0\n",
       "Year                  0\n",
       "Quarter               0\n",
       "Pincode               0\n",
       "Transaction_count     0\n",
       "Transaction_amount    0\n",
       "Region                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'top_trans_pin_df' seems to have two null values and they are not of significant proportion so dropping them;\n",
    "\n",
    "top_trans_pin_df.dropna(axis = 'index', inplace = True)\n",
    "top_trans_pin_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing datatype across all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7cdac0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    if 'Year' in df.columns:\n",
    "        df['Year'] = df['Year'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61bf7e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64\n",
      "Int64\n",
      "Int64\n",
      "Int64\n",
      "Int64\n",
      "Int64\n",
      "Year column not found in dataframe: lat_long_df\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    if 'Year' in df.columns:\n",
    "        df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "        df['Year'] = df['Year'].astype('Int64')\n",
    "        print(df['Year'].dtype)\n",
    "        globals()[df_name] = df\n",
    "    else:\n",
    "        print(\"Year column not found in dataframe:\", df_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cdd537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier count across all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16424d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything seems to be alright as far as dtypes and nullvalues are concerned so checking for outliers\n",
    "# Function to check for outliers\n",
    "\n",
    "def count_outliers(df):\n",
    "    outliers = {}\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        if col in ['Transaction_count', 'Transaction_amount']:\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            upper_bound = q3 + (1.5 * iqr)\n",
    "            lower_bound = q1 - (1.5 * iqr)\n",
    "            outliers[col] = len(df[(df[col] > upper_bound) | (df[col] < lower_bound)])\n",
    "        else:\n",
    "            continue\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3eaecf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTLIER COUNT ACROSS DATAFRAMES:\n",
      "\n",
      "agg_trans_df :\n",
      "\n",
      " {'Transaction_count': 652, 'Transaction_amount': 660} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "agg_user_df :\n",
      "\n",
      " {'Transaction_count': 893} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "map_trans_df :\n",
      "\n",
      " {'Transaction_count': 1811, 'Transaction_amount': 1771} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_dist_df :\n",
      "\n",
      " {'Transaction_count': 734, 'Transaction_amount': 743} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_pin_df :\n",
      "\n",
      " {'Transaction_count': 999, 'Transaction_amount': 995} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('OUTLIER COUNT ACROSS DATAFRAMES:\\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    outliers = count_outliers(df)\n",
    "    if len(outliers) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        print(df_name, \":\\n\\n\", outliers, \"\\n\")\n",
    "        print(\"\\n\", 55 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88ffbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique value count across all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "56360e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for unique value counts and print if count less than 10;\n",
    "\n",
    "def unique_value_count(df, exclude_cols=[]):\n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        unique_vals = df[col].nunique()\n",
    "        print(f\"{col}: {unique_vals} unique values\")\n",
    "        if unique_vals < 10:\n",
    "            print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d4203d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE VALUE COUNT ACROSS DATAFRAMES; \n",
      "\n",
      "agg_trans_df :\n",
      "\n",
      "Transaction_type: 5 unique values\n",
      "['Recharge & bill payments' 'Peer-to-peer payments' 'Merchant payments'\n",
      " 'Financial Services' 'Others']\n",
      "Transaction_count: 3548 unique values\n",
      "Transaction_amount: 3594 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "agg_user_df :\n",
      "\n",
      "Brand: 20 unique values\n",
      "Transaction_count: 6501 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "map_trans_df :\n",
      "\n",
      "District: 727 unique values\n",
      "Transaction_count: 14566 unique values\n",
      "Transaction_amount: 14636 unique values\n",
      "Latitude: 533 unique values\n",
      "Longitude: 540 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "map_user_df :\n",
      "\n",
      "District: 727 unique values\n",
      "Registered_users: 14351 unique values\n",
      "App_opens: 10977 unique values\n",
      "Latitude: 533 unique values\n",
      "Longitude: 540 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_dist_df :\n",
      "\n",
      "District: 368 unique values\n",
      "Transaction_count: 5910 unique values\n",
      "Transaction_amount: 5920 unique values\n",
      "Latitude: 300 unique values\n",
      "Longitude: 299 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_pin_df :\n",
      "\n",
      "Pincode: 746 unique values\n",
      "Transaction_count: 7083 unique values\n",
      "Transaction_amount: 7137 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_user_dist_df :\n",
      "\n",
      "District: 313 unique values\n",
      "Registered_users: 5874 unique values\n",
      "Latitude: 258 unique values\n",
      "Longitude: 258 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_user_pin_df :\n",
      "\n",
      "Pincode: 426 unique values\n",
      "Registered_users: 6882 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "lat_long_df :\n",
      "\n",
      "District: 727 unique values\n",
      "Latitude: 533 unique values\n",
      "Longitude: 540 unique values\n",
      "Region: 6 unique values\n",
      "['Southern Region' 'North-Eastern Region' 'Eastern Region'\n",
      " 'Northern Region' 'Central Region' 'Western Region']\n",
      "\n",
      " _______________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('UNIQUE VALUE COUNT ACROSS DATAFRAMES; \\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(df_name, \":\\n\")\n",
    "    unique_value_count(df, exclude_cols = ['State', 'Year', 'Quarter', 'Percentage'])\n",
    "    print(\"\\n\", 55 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "09752b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_value_count(df, exclude_cols=None):\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        unique_vals = df[col].nunique()\n",
    "        print(f\"{col}: {unique_vals} unique values\")\n",
    "        if unique_vals < 10:\n",
    "            print(df[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Though outliers haven't gave much of an insight, unique value count can be used to gain some good insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "09cb35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dfs_as_csv(df_list):\n",
    "    subfolder = 'Miscellaneous'\n",
    "    if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "        \n",
    "    for df_name in df_list:\n",
    "        df = globals()[df_name]\n",
    "        file_path = os.path.join(subfolder, df_name.replace('_df', '') + '.csv')\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "# Calling function to execute\n",
    "\n",
    "save_dfs_as_csv(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f852de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2760b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establishing connection and creating cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "117e1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(\n",
    "  host = \"localhost\",\n",
    "  user = \"root\",\n",
    "  password = \"Samuel@151299\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ee8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor.execute(\"DROP DATABASE IF EXISTS phonepe_pulse\")\n",
    "\n",
    "cursor.execute(\"CREATE DATABASE phonepe_pulse\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "04c200b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"USE phonepe_pulse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a563faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating tables\n",
    "State\tYear\tQuarter\tTransaction_type\tTransaction_count\tTransaction_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5f979d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''CREATE TABLE IF NOT EXISTS agg_trans (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Transaction_type VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Transaction_type(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS agg_user (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Brand VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Percentage FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Brand(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS map_trans (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,\n",
    "                    Latitude FLOAT,\n",
    "                    Longitude FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS map_user (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Registered_users INTEGER,\n",
    "                    App_opens INTEGER,\n",
    "                    Latitude FLOAT,\n",
    "                    Longitude FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS top_trans_dist (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,\n",
    "                    Latitude FLOAT,\n",
    "                    Longitude FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS top_trans_pin (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Pincode VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Pincode(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS top_user_dist (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Registered_users INTEGER,\n",
    "                    Latitude FLOAT,\n",
    "                    Longitude FLOAT,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255), Region(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS top_user_pin (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Pincode VARCHAR(255),\n",
    "                    Registered_users INTEGER,\n",
    "                    Region VARCHAR(255),\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Pincode(255), Region(255))\n",
    "                 )''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bc950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pushing data into MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd651ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_data_into_mysql(conn, cursor, dfs, table_columns):\n",
    "    for table_name in dfs.keys():\n",
    "        df = dfs[table_name]\n",
    "        columns = table_columns[table_name]\n",
    "        placeholders = ', '.join(['%s'] * len(columns))\n",
    "        query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders})\"\n",
    "        for _, row in df.iterrows():\n",
    "            data = tuple(row[column] for column in columns)\n",
    "            cursor.execute(query, data)\n",
    "        conn.commit()\n",
    "    print(\"Data successfully pushed into MySQL tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8ffd0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping my_sql tables to pandas dataframes that we have created earlier\n",
    "\n",
    "dfs = {\n",
    "    'agg_trans': agg_trans_df,\n",
    "    'agg_user': agg_user_df,\n",
    "    'map_trans': map_trans_df,\n",
    "    'map_user': map_user_df,\n",
    "    'top_trans_dist': top_trans_dist_df,\n",
    "    'top_trans_pin': top_trans_pin_df,\n",
    "    'top_user_dist': top_user_dist_df,\n",
    "    'top_user_pin': top_user_pin_df\n",
    "}\n",
    "\n",
    "# Mapping table name to associated columns for each table\n",
    "\n",
    "table_columns = {\n",
    "    'agg_trans': list(agg_trans_df.columns),\n",
    "    'agg_user': list(agg_user_df.columns),\n",
    "    'map_trans': list(map_trans_df.columns),\n",
    "    'map_user': list(map_user_df.columns),\n",
    "    'top_trans_dist': list(top_trans_dist_df.columns),\n",
    "    'top_trans_pin': list(top_trans_pin_df.columns),\n",
    "    'top_user_dist': list(top_user_dist_df.columns),\n",
    "    'top_user_pin': list(top_user_pin_df.columns)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "82836094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully pushed into MySQL tables\n"
     ]
    }
   ],
   "source": [
    "push_data_into_mysql(conn, cursor, dfs, table_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "51f77bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_trans table has 3594 rows and 7 columns and shape matches DataFrame.\n",
      "agg_user table has 6732 rows and 7 columns and shape matches DataFrame.\n",
      "map_trans table has 14636 rows and 9 columns and shape matches DataFrame.\n",
      "map_user table has 14640 rows and 9 columns and shape matches DataFrame.\n",
      "top_trans_dist table has 5920 rows and 9 columns and shape matches DataFrame.\n",
      "top_trans_pin table has 7137 rows and 7 columns and shape matches DataFrame.\n",
      "top_user_dist table has 5920 rows and 8 columns and shape matches DataFrame.\n",
      "top_user_pin table has 7140 rows and 6 columns and shape matches DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Get list of tables in database\n",
    "\n",
    "cursor.execute(\"SHOW TABLES\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Loop through tables and get count of rows and columns in MySQL\n",
    "\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "    row_count = cursor.fetchone()[0]\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM information_schema.columns WHERE table_name='{table_name}'\")\n",
    "    column_count = cursor.fetchone()[0]\n",
    "\n",
    "    # Check if shape of DataFrame matches count of rows and columns in table\n",
    "\n",
    "    df = dfs[table_name]\n",
    "    if df.shape == (row_count, column_count):\n",
    "        print(f\"{table_name} table has {row_count} rows and {column_count} columns and shape matches DataFrame.\")\n",
    "    else:\n",
    "        print(f\"{table_name} table has {row_count} rows and {column_count} columns but shape does not match DataFrame.\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
